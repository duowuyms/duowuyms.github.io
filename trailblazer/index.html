
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SizeGS</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://shuzhaoxie.github.io/mesongs/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://duowuyms.github.io/trailblazer/"/>
    <meta property="og:title" content="Large Language Models as Generalist Policies for Network Optimization" />

    <!-- <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="SizeGS: Size-aware Compression of 3D Gaussians\\with Hierarchical Mixed Precision Quantization" />
    <meta name="twitter:description" content="3D Gaussian Splatting demonstrates excellent quality and speed in novel view synthesis. Nevertheless, the significant size of the 3D Gaussians presents challenges for transmission and storage. Current approaches employ compact models to compress the substantial volume and attributes of 3D Gaussians, along with intensive training to uphold quality. These endeavors demand considerable finetuning time, presenting formidable hurdles for practical deployment. To this end, we propose MesonGS, a codec for post-training compression of 3D Gaussians. Initially, we introduce a measurement criterion that considers both view-dependent and view-independent factors to assess the impact of each Gaussian point on the rendering output, enabling the removal of insignificant points. Subsequently, we decrease the entropy of attributes through two transformations that complement subsequent entropy coding techniques to enhance the file compression rate. More specifically, we first replace the rotation quaternion with Euler angles; then, we apply region adaptive hierarchical transform (RAHT) to key attributes to reduce entropy. Lastly, we suggest block quantization to control quantization granularity, thereby avoiding excessive information loss caused by quantization. Moreover, a finetune scheme is introduced to restore quality. Extensive experiments demonstrate that MesonGS significantly reduces the size of 3D Gaussians while preserving competitive quality." />
    <meta name="twitter:image" content="https://shuzhaoxie.github.io/mesongs/img/teaser.jpg" /> -->


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>âš¡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Large Language Models as Generalist Policies for Network Optimization</b>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://duowuyms.github.io">
                          Duo Wu<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        Linjia Kang<sup>1</sup>
                    </li>
                    <li>
                        <a href="https://zhiminwangss.github.io/">
                            Zhimin Wang<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html">
                            Fangxin Wang<sup>2</sup>
                        </a>
                    </li>
                    <li>
                        Wei Zhang<sup>3</sup>
                    </li>
                    <li>
                        Xuefeng Tao<sup>3</sup>
                    </li>
                    <li>
                        Wei Yang<sup>3</sup>
                    </li>
                    <li>
                        Le Zhang<sup>3</sup>
                    </li>
                    <li>
                        <a href="https://pengcui.thumedialab.com/">
                          Peng Cui<sup>4</sup>
                        </a>
                    </li>
                    <li>
                        <a href="http://zwang.inflexionlab.org">
                          Zhi Wang<sup>1</sup>*
                        </a>
                    </li>
                </br> <sup>1</sup>Shenzhen International Graduate School, Tsinghua University <br>
                    <sup>2</sup>School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen</br> 
                    <sup>3</sup>Bytedance</br>
                    <sup>4</sup>Department of Computer Science and Technology, Tsinghua University<br>
                    *Corresponding Author
                </ul>
            </div>
        </div>
        

        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://github.com/duowuyms/Trailblazer">
                            <image src="img/trailblazer_paper.png" height="40px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="../data/24-eccv-mesongs-supp.pdf">
                            <image src="img/mesongs_paper_image.png" height="40px">
                                <h4><strong>Supplyment</strong></h4>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://github.com/duowuyms/Trailblazer">
                            <image src="img/github.png" height="40px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="">
                            <image src="img/database_icon.png" height="40px">
                                <h4><strong>Original .ply files</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="">
                            <image src="img/database_icon.png" height="40px">
                                <h4><strong>Evaluation images</strong></h4>
                            </a>
                        </li> -->
                    </ul>
                </div>
        </div>
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <img src="img/trailblazer.png" alt="Trailblazer" id="v0" width="100%" autoplay loop muted controls>
                <p class="text-justify">
                <b>Trailblazer (å¼€æ‹“è€…) is the pioneering framework that grounds LLMs as generalist policies for network optimization to achieve strong generalization across diverse tasks and environments.</b>
                </p>
            </div>
          
        </div>
          <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    Trailblazer signifies our goal of forging the first path in LLM-driven generalist network policies, establishing a framework for both academia and industry to advance the integration of LLMs into real-world network services. ðŸ˜Š
                </p>
            </div>
        </div> 
          
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Abstract</b>
                </h3>
                <p class="text-justify">
                    Designing control policies to ensure robust network services is essential to modern digital infrastructure. However, the dominant paradigm for network optimization relies on designing specialist policies based on handcrafted rules or deep learning models, leading to poor generalization across diverse tasks and environments. In contrast, large language models (LLMs), pretrained on Internet-scale corpora, provide a rich and unified knowledge base that encodes fundamental networking principles. Combined with their emergent abilities in generalization to unseen scenarios, LLMs offer a transformative foundation for generalist network policies that can generalize across diverse tasks and environments with minimal adaptation. In this paper, we present Trailblazer, the first systematic framework to realize such a generalist policy for networking. Trailblazer incorporates a network alignment scheme to ground the LLM in specific networking tasks, and an adaptive policy collaboration mechanism that offloads simple control cases from the LLM to a lightweight policy for computational efficiency. Through extensive simulations and large-scale real-world online evaluation on Douyin (the Chinese version of TikTok), Trailblazer, powered by a single LLM, demonstrates stronger cross-task and cross-environment generalization than conventional specialist policies. Our results validate LLMs as the foundation for generalist network policies, and position Trailblazer as the first step toward the generalist-driven paradigm that enables strong generalization with minimal efforts in policy design.                </p>
                </p>
                <br>
                    <p class="text-justify">
                        <img src="img/key_finding.png" alt="Trailblazer" id="v0" width="100%" autoplay loop muted controls>
                    <b>Key findings of this paper.</b> The generalist-driven paradigm established by Trailblazer leverages a single LLMâ€“equipped with strong generalization abilities and a shared knowl edge base encoding universal networking principlesâ€“to enable low-effort policy design and achieve strong cross-task and cross-environment generalization.
                </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Method</b>
                </h3>
                <br>
                    <p class="text-justify">
                        <img src="img/method.png" alt="Trailblazer" id="v0" width="100%" autoplay loop muted controls>
                    <b>Overview of our proposed framework Trailblazer.</b> (Up) The NIOKA in Trailblazer to
                    address the misalignment between the LLM and networking. The network state encoder is introduced
                    to project non-textual network information into the same feature space as language tokens for the
                    LLM, while the network action decoder is used to map the LLM output feature vectors into specific
                    network actions. Based on the proposed offline reinforcement fine-tuning algorithm, the LLM is fine-tuned over an offline experience dataset collected by evaluating conventional network policies across
                    diverse network environments, with rewards or near-optimal actions as the guiding signals. (Low) The
                    APC in Trailblazer for efficient LLM deployment, where the fine-tuned LLM collaborates with a
                    conventional policy for intelligent and efficient network control. The heart of APC is a scheduler for
                    adaptively flow request routing. The scheduler evaluates the network conditions of each request (e.g.,
                    latency). Requests under poor conditions are deemed as difficult cases and allocated to the LLM for
                    intelligent control, while those under stable conditions are handled by a conventional policy for fast
                    processing. To reduce the per-request processing latency, the LLM will process requests in batches.
                </div>
        </div>
  
        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Hyperparameter Search Algorithm
                </h3>
                
				<table style="width: 100%; border-collapse: collapse;">
				  <tr>
				    <td style="text-align: center;">
		                <image  src="img/mesongs_framework.png" width="100%"></image>
					</td>
				  </tr>
				</table>
                <br>
                <p class="text-justify">
                    1) We prune insignificant Gaussians by considering both view-dependent and view-independent factors. 2) Geometry compression is performed using an octree to generate voxelized coordinates for future transformations. 3) We replace rotation quaternions with Euler angles. 4) Applying RAHT and 5) block quantization to important attributes. Notably, RAHT is not applied to the scales when the quantization bit is 8 (<em>see dashed arrow</em>). 6) To significantly compress the remained SH coefficients, vector quantization is employed. 7) All components are packed by <em>zip</em>.
                </p>
            </div>
        </div>
<br> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Results</b>
                </h3>
                <p class="text-justify">
                    We compare our generalist approach Trailblazer powered by a single LLM with  task-specific policies on two represenative tasks (adaptive bitrate streaming ABR, cluster job scheduling CJS) and heterogeneous environments.</p>                    
                </p>
                <br>
                <b><i>Finding 1: Trailblazer successfully generalizes across heterogeneous tasks with a single LLM.</i></b>
                <img width="100%" src="./img/cross_task_gen.png"/>
                <p class="text-justify">
                     Conventional specialist policies fail to generalize across different tasks due to the task-specific design. By copmarison, powered
                        by a single LLM, Trailblazer successfully generalizes across heterogeneous networking tasks, achieving stronger cross-task generalization. These results demonstrate that LLMs can serve as a unified foundation for generalist network policies, breaking the
                        task-isolation barrier of the specialist paradigm.
                </p>

                <br>
                <b><i>Finding 2: Trailblazer achieves stronger generalization than specialist policies across heterogeneous environments.</i></b>
                <img width="100%" src="./img/cross_env_gen.png"/>
                <p class="text-justify">
                    To assess whether a generalist policy can achieve stronger cross-environment generalization, we evaluate Trailblazer across 
                    various challenging out-of-distribution (OOD) test environments. By leveraging the strong consistently outperforms all baselines in terms of average values
                    and distributions across all cases. 
                </p>

                <br>
                <b><i>Finding 3: Trailblazer can not only operate reliably in production network environments but also introduce industrial improvements in service quality.</i></b>
                <img width="100%" src="./img/real_world.png"/>
                <p class="text-justify">
                    We deploy Trailblazer in Douyinâ€™s real-time congestion control (CC) service for large-scale online A/B tests over three weeks, serving 150,000+ users across 100+ cities and accumulating over 1,200 days of video playback time. 
                    Results show that Trailblazer outperform VICC, a highly optimized policy designed for Douyin, in  key industrial performance metrics.
                </p>

                
            </div>
        </div> 
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Insights</b>
                </h3>
                <b><i>Insight 1 - Early Saturation</i></b> 
                <img width="100%" src="./img/early_saturation.png"/>
                <p class="text-justify">
                    Unlike the scaling law in NLP, small-scale LLMs can achieve strong generalization in networking. Hence, we can trade efficiency with small LLMs without sacrificing performance.
                </p>
                <br>
                <b><i>Insight 2 - Selective Invocation</i></b> 
                <img width="100%" src="./img/selective_invocation.png"/>
                <p class="text-justify">
                    Selectively invoking the LLM can boost efficiency without compromising performance. Hence, this reveals an important principle: invoking the LLM for network control
                    when necessary rather than implementing per-request control.
                </p>
            </div>
        </div> 

        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Citation</b>
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@inproceedings{xie2024sizegs,
    title={SizeGS: Size-aware Compression of 3D Gaussian Splatting via Mixed Integer Programming},
    author={Xie, Shuzhao and Liu, Jiahang and Zhang, Weixiang and Ge, Shijia and Pan, Sicheng and Tang, Chen and Bai, Yunpeng and Zhang, Cong and Fan, Xiaoyi and Wang, Zhi},
    booktitle={ACM MM},
    year={2025}
}
                </textarea>
                </div>
            </div>
        </div>

    </div>
</body>
</html>
